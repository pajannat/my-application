{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考  \n",
    "https://notebooks.githubusercontent.com/view/ipynb?browser=unknown_browser&color_mode=auto&commit=b34f8964fe3cdbbf0dd527dc381926721538ac8c&device=unknown_device&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f6d617473756f6c61622d6564752f646c3475732f623334663839363466653363646262663064643532376463333831393236373231353338616338632f6c6573736f6e342f6c6573736f6e345f736563325f65786572636973652e6970796e62&logged_in=false&nwo=matsuolab-edu%2Fdl4us&path=lesson4%2Flesson4_sec2_exercise.ipynb&platform=unknown_platform&repository_id=179020903&repository_type=Repository&version=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 実装①\n",
    "LSTMを使ったSeq2Seqモデルで 文章→ぺこらポエム 変換を行う。  \n",
    "使用するデータセット、train.sentenceとtrain.poemの中身は次のようになっています.  \n",
    "train.sentenceの中身 (ポエムの要約)\n",
    "\n",
    "凄いと噂のIDサバも見たいし、今年もあるんだー。あと、夏祭りの予習もしないと！（笑  \n",
    "︙\n",
    "\n",
    "train.poemの中身(要約前のポエム)\n",
    "\n",
    "今日は久しぶりのマイクラ❣  凄いと噂のID鯖も見てみたいし 今年もあります！夏祭りの下準備もしなければ！  欲張りぺこーらぺこおおおおおお✨✨  \n",
    "︙"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの用意\n",
    "まずはデータの読み込みです。\n",
    "読み込む際、文頭を表す仮想単語（BOS, Beginning Of Sentence）として\\<s>、文末を表す仮想単語（EOS, End Of Sentence）として<\\s>を付加します。\n",
    "また、BOS, EOSをつけた文章について、Tokenizerによって数値化を行います。\n",
    "最後に、バッチ処理のため、各系列の長さをそろえておきます。これにはkeras.preprocessing.sequence.pad_sequencesを用います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def load_data(file_path):\n",
    "    tokenizer = Tokenizer(filters=\"\")\n",
    "    whole_texts = []\n",
    "    for line in open(file_path, encoding='utf-8'):\n",
    "        whole_texts.append(\"<s> \" + line.strip() + \" </s>\")\n",
    "        \n",
    "    tokenizer.fit_on_texts(whole_texts)\n",
    "    \n",
    "    return tokenizer.texts_to_sequences(whole_texts), tokenizer\n",
    "\n",
    "# 読み込み＆Tokenizerによる数値化\n",
    "x_train, tokenizer_en = load_data('./data/train.sentence.txt')\n",
    "y_train, tokenizer_ja = load_data('./data/train.poem.txt')\n",
    "\n",
    "en_vocab_size = len(tokenizer_en.word_index) + 1\n",
    "ja_vocab_size = len(tokenizer_ja.word_index) + 1\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# パディング\n",
    "x_train = pad_sequences(x_train, padding='post')\n",
    "y_train = pad_sequences(y_train, padding='post')\n",
    "\n",
    "seqX_len = len(x_train[0])\n",
    "seqY_len = len(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル構築\n",
    "ここでは、LSTMを使用してSeq2Seqモデルを構築します。  \n",
    "Embeddingレイヤーではmask_zero=Trueを引数として指定することで、計算上先程のパディング部分を無視するようにしています。  \n",
    "また、Recurrentレイヤーに対するreturn_state=Trueやreturn_sequences=Trueの指定をLSTMレイヤーの生成時に行っています。  \n",
    "なお、Functional APIによるモデル構築であることに注意してください。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, LSTM\n",
    "\n",
    "emb_dim = 256\n",
    "hid_dim = 256\n",
    "\n",
    "## 符号化器\n",
    "# Inputレイヤー（返り値としてテンソルを受け取る）\n",
    "encoder_inputs = Input(shape=(seqX_len,))\n",
    "\n",
    "# モデルの層構成（手前の層の返り値テンソルを、次の接続したい層に別途引数として与える）\n",
    "# InputレイヤーとEmbeddingレイヤーを接続（+Embeddingレイヤーのインスタンス化）\n",
    "encoder_embedded = Embedding(en_vocab_size, emb_dim, mask_zero=True)(encoder_inputs) # shape: (seqX_len,)->(seqX_len, emb_dim)\n",
    "# EmbeddingレイヤーとLSTMレイヤーを接続（+LSTMレイヤーのインスタンス化）\n",
    "_, *encoder_states = LSTM(hid_dim, return_state=True)(encoder_embedded)  # shape: (seqX_len, emb_dim)->(hid_dim, )\n",
    "# このLSTMレイヤーの出力に関しては下記に補足あり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 復号化器\n",
    "# Inputレイヤー（返り値としてテンソルを受け取る）\n",
    "decoder_inputs = Input(shape=(seqY_len,))\n",
    "\n",
    "# モデルの層構成（手前の層の返り値テンソルを、次の接続したい層に別途引数として与える）\n",
    "# InputレイヤーとEmbeddingレイヤーを接続\n",
    "decoder_embedding = Embedding(ja_vocab_size, emb_dim) # 後で参照したいので、レイヤー自体を変数化\n",
    "decoder_embedded = decoder_embedding(decoder_inputs)  # shape: (seqY_len,)->(seqY_len, emb_dim)\n",
    "# EmbeddingレイヤーとLSTMレイヤーを接続（encoder_statesを初期状態として指定）\n",
    "decoder_lstm = LSTM(hid_dim, return_sequences=True, return_state=True) # 後で参照したいので、レイヤー自体を変数化\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedded, initial_state=encoder_states) # shape: (seqY_len, emb_dim)->(seqY_len, hid_dim)\n",
    "# LSTMレイヤーとDenseレイヤーを接続\n",
    "decoder_dense = Dense(ja_vocab_size, activation='softmax') # 後で参照したいので、レイヤー自体を変数化\n",
    "decoder_outputs = decoder_dense(decoder_outputs) # shape: (seqY_len, hid_dim)->(seqY_len, ja_vocab_size)\n",
    "\n",
    "# モデル構築（入力は符号化器＆復号化器、出力は復号化器のみ）\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "# 今回は、sparse_categorical_crossentropy（正解ラベルとしてone_hot表現のベクトルでなく数値を受け取るcategorical_crossentropy）を使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの学習\n",
    "モデルの学習時には、教師データとして1時点先の単語を示すデータを入力します。(train_target)  \n",
    "学習時にはDecoderの入力に教師データを用います。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "31/31 - 7s - loss: 3.9871 - val_loss: 3.6470 - 7s/epoch - 213ms/step\n",
      "Epoch 2/20\n",
      "31/31 - 1s - loss: 3.3459 - val_loss: 3.6959 - 1s/epoch - 35ms/step\n",
      "Epoch 3/20\n",
      "31/31 - 1s - loss: 3.1461 - val_loss: 3.9964 - 1s/epoch - 36ms/step\n",
      "Epoch 4/20\n",
      "31/31 - 1s - loss: 3.0424 - val_loss: 4.2559 - 1s/epoch - 35ms/step\n",
      "Epoch 5/20\n",
      "31/31 - 1s - loss: 2.9586 - val_loss: 4.2383 - 1s/epoch - 36ms/step\n",
      "Epoch 6/20\n",
      "31/31 - 1s - loss: 2.8808 - val_loss: 4.7319 - 1s/epoch - 35ms/step\n",
      "Epoch 7/20\n",
      "31/31 - 1s - loss: 2.7851 - val_loss: 4.5280 - 1s/epoch - 35ms/step\n",
      "Epoch 8/20\n",
      "31/31 - 1s - loss: 2.6976 - val_loss: 5.4353 - 1s/epoch - 36ms/step\n",
      "Epoch 9/20\n",
      "31/31 - 1s - loss: 2.6166 - val_loss: 5.5986 - 1s/epoch - 35ms/step\n",
      "Epoch 10/20\n",
      "31/31 - 1s - loss: 2.5466 - val_loss: 5.7276 - 1s/epoch - 36ms/step\n",
      "Epoch 11/20\n",
      "31/31 - 1s - loss: 2.4453 - val_loss: 5.9013 - 1s/epoch - 35ms/step\n",
      "Epoch 12/20\n",
      "31/31 - 1s - loss: 2.3765 - val_loss: 6.4508 - 1s/epoch - 37ms/step\n",
      "Epoch 13/20\n",
      "31/31 - 1s - loss: 2.3026 - val_loss: 6.6712 - 1s/epoch - 36ms/step\n",
      "Epoch 14/20\n",
      "31/31 - 1s - loss: 2.2166 - val_loss: 6.6342 - 1s/epoch - 36ms/step\n",
      "Epoch 15/20\n",
      "31/31 - 1s - loss: 2.1510 - val_loss: 6.7379 - 1s/epoch - 36ms/step\n",
      "Epoch 16/20\n",
      "31/31 - 1s - loss: 2.0833 - val_loss: 6.9686 - 1s/epoch - 36ms/step\n",
      "Epoch 17/20\n",
      "31/31 - 1s - loss: 2.0276 - val_loss: 6.9785 - 1s/epoch - 36ms/step\n",
      "Epoch 18/20\n",
      "31/31 - 1s - loss: 1.9489 - val_loss: 7.2480 - 1s/epoch - 35ms/step\n",
      "Epoch 19/20\n",
      "31/31 - 1s - loss: 1.8717 - val_loss: 7.1181 - 1s/epoch - 36ms/step\n",
      "Epoch 20/20\n",
      "31/31 - 1s - loss: 1.8055 - val_loss: 7.2027 - 1s/epoch - 35ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cab9205520>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_target = np.hstack((y_train[:, 1:], np.zeros((len(y_train),1), dtype=np.int32)))\n",
    "\n",
    "model.fit([x_train, y_train], np.expand_dims(train_target, -1), batch_size=2, epochs=20, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルによる生成\n",
    "先程学習したモデルを使用して、系列を生成してみましょう。  \n",
    "そのためにまずは学習したモデルを組み込んだ、系列生成用のモデルを構築します。  \n",
    "学習時との違いは、復号化器が1ステップずつ実行できるよう、状態ベクトルの入力と出力をモデルの定義に加えている点です。  \n",
    "(また、1ステップ前の状態を引き継いで生成が可能になるように、復号化器のモデルの初期状態を指定可能にしています。)  \n",
    "生成する際のDecoderの入力には翻訳先の教師データは用いません。  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプリング用（生成用）のモデルを作成\n",
    "\n",
    "# 符号化器（学習時と同じ構成、学習したレイヤーを利用）\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# 復号化器\n",
    "decoder_states_inputs = [Input(shape=(hid_dim,)), Input(shape=(hid_dim,))] # decorder_lstmの初期状態指定用(h_t, c_t)\n",
    "\n",
    "decoder_inputs = Input(shape=(1,))\n",
    "decoder_embedded = decoder_embedding(decoder_inputs) # 学習済みEmbeddingレイヤーを利用\n",
    "decoder_outputs, *decoder_states = decoder_lstm(decoder_embedded, initial_state=decoder_states_inputs) # 学習済みLSTMレイヤーを利用\n",
    "decoder_outputs = decoder_dense(decoder_outputs) # 学習済みDenseレイヤーを利用\n",
    "\n",
    "decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルを使用した生成（予測）\n",
    "生成では、未知のデータに対してモデルを適用するので正解ラベルはわかりません。  \n",
    "そこで、代わりに前のステップで予測した単語を各ステップでの入力とします。  \n",
    "そして, 系列の終わりを表す単語 (\\</s>) が出力されるまで繰り返します。（最初の入力は\\<s>を使用します）  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, bos_eos, max_output_length = 1000):\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    target_seq = np.array(bos_eos[0])  # bos_eos[0]=\"<s>\"に対応するインデックス\n",
    "    output_seq= bos_eos[0][:]\n",
    "    \n",
    "    while True:\n",
    "        output_tokens, *states_value = decoder_model.predict([target_seq] + states_value)\n",
    "        sampled_token_index = [np.argmax(output_tokens[0, -1, :])]\n",
    "        output_seq += sampled_token_index\n",
    "        \n",
    "        if (sampled_token_index == bos_eos[1] or len(output_seq) > max_output_length):\n",
    "            break\n",
    "\n",
    "        target_seq = np.array(sampled_token_index)\n",
    "\n",
    "    return output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "元の文: <s> ペコラはロケランで何でも破壊してしまうパワフルな女の子です。彼女は仲間になる人を探している。報酬はすべて彼女のものです。 </s>\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "生成文: <s> 前回苦しめられたウォーデン… 伝説の料理「龍の髭」を!!!!!! 1本…2本…4本…8本…16本… 最後には1万6千本以上の髭を作るぺこ💪✨ 新人龍の髭職人ぺこーらの技をご覧あれ！ </s>\n",
      "正解文: <s> げきうま！げきうま！やばいぐらい物資がうますぎるらしい これはいくしかないぺこだよね？ 危険？危ない？お前じゃ無理だ。 おいおい、何言ってんだい。 ぺこーらの右腕みえねえのか。 このロケランですべてを破壊してやるよ。 ともについてくるやつがいるならついてこい！ 報酬はすべてぺこらのもの </s>\n"
     ]
    }
   ],
   "source": [
    "detokenizer_en = dict(map(reversed, tokenizer_en.word_index.items()))\n",
    "detokenizer_ja = dict(map(reversed, tokenizer_ja.word_index.items()))\n",
    "\n",
    "text_no = 8\n",
    "input_seq = pad_sequences([x_test[text_no]], seqX_len, padding='post')\n",
    "bos_eos = tokenizer_ja.texts_to_sequences([\"<s>\", \"</s>\"])\n",
    "\n",
    "print('元の文:', ' '.join([detokenizer_en[i] for i in x_test[text_no]]))\n",
    "print('生成文:', ' '.join([detokenizer_ja[i] for i in decode_sequence(input_seq, bos_eos)]))\n",
    "print('正解文:', ' '.join([detokenizer_ja[i] for i in y_test[text_no]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('py37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5da9aad921784b8644505a50d90de01e1bbce0d7772509339b5714d1cab40d5a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
